from aiogram import html
from aiogram.types import BufferedInputFile, InputFile

from app.src.services.db.dao.holder import HolderDao
from app.src.services.db.models import Dialog, TTSVoice
from app.src.services.markdown import escape_special_characters_in_place_text
from app.src.services.openai import (
    get_image_from_gpt,
    get_response_from_gpt,
    text_to_speech,
)


async def _get_messages_to_request(
    dao: HolderDao, user_id: int, text: str
) -> list[dict[str, str]]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –≤ openai –∏–∑ –±–∞–∑—ã –∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∏—Ö —Å —Ç–µ–∫—É—â–∏–º –∑–∞–ø—Ä–æ—Å–æ–º."""
    dialogs = await dao.dialog.find_all(user_id=user_id)
    messages = [{"role": dialog.role, "content": dialog.content} for dialog in dialogs]
    messages.append({"role": "user", "content": text})
    await dao.dialog.add(Dialog(user_id=user_id, role="user", content=text))
    return messages


async def add_role_for_dialog(dao: HolderDao, user_id: int, text: str):
    """–î–æ–≤–∞–±–ª–µ–Ω–∏–µ —Ä–æ–ª–∏ –¥–ª—è –¥–∏–∞–ª–æ–≥–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö."""
    await dao.dialog.add(Dialog(user_id=user_id, role="system", content=text))


async def response_from_gpt(dao: HolderDao, user_id: int, message: str) -> str:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç openai, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –µ–≥–æ –≤ –ë–î."""
    messages_to_request = await _get_messages_to_request(dao, user_id, message)
    response = await get_response_from_gpt(messages_to_request)
    if response is None:
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç"
    await dao.dialog.add(
        Dialog(user_id=user_id, role="assistant", content=html.quote(response))
    )
    return escape_special_characters_in_place_text(response)


async def response_audio(
    dao: HolderDao, user_id: int, text: str
) -> InputFile | None:
    """–ü–æ–ª—É—á–∞–µ—Ç –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ –æ—Ç openai –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–∏–≤–∞–µ—Ç
    –∏—Ö –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —á–µ—Ä–µ–∑ –¢–ì.
    """
    settings = await dao.settings.find_one(id=user_id)
    if settings.tts_voice == TTSVoice.NOT_SELECT:
        return
    response = await text_to_speech(text, settings.tts_voice.value)
    return BufferedInputFile(response, "audio")


async def generate_image(dao: HolderDao, user_id: int, text: str) -> str | None:
    settings = await dao.settings.find_one(id=user_id)
    return await get_image_from_gpt(
        text, settings.image_format.value, settings.image_style.value
    )


async def clear_dialog_context(dao: HolderDao, user_id: int):
    """–û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞ –∏ —Ä–æ–ª–∏."""
    await dao.dialog.delete(user_id=user_id)


# async def show_generation_status(wait_message: Message):
#     """–°–æ–∑–¥–∞–µ—Ç –¥–∏–Ω–∞–º–∏—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–æ —Å–º–µ–Ω–∞—é—â–∏–º–∏—Å—è —Å—Ç–∞—Ç—É—Å–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞"""
#     animation_frames = [
#         "‚†Ä\n‚è≥ –ó–∞–ø—Ä–æ—Å –ø—Ä–∏–Ω—è—Ç –≤ –æ–±—Ä–∞–±–æ—Ç–∫—É...\n‚†Ä",
#         "‚†Ä\n‚ùáÔ∏è –ì–æ—Ç–æ–≤–∏—Ç—Å—è –æ—Ç–≤–µ—Ç...\n‚†Ä",
#         # "‚†Ä\nüó£ –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç—Å—è –≥–æ–ª–æ—Å...\n‚†Ä",
#     ]
#     frame_index = 0
#     while True:
#         await asyncio.sleep(1)
#         try:
#             await wait_message.edit_text(animation_frames[frame_index])
#             frame_index = (frame_index + 1) % len(animation_frames)
#         except TelegramRetryAfter:
#             await asyncio.sleep(1)
#         except TelegramBadRequest:
#             frame_index = (frame_index + 1) % len(animation_frames)
#             await wait_message.answer(animation_frames[frame_index])
